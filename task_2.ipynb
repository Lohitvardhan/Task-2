{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b3e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Deep Learning LSTM Model - Task 2\n",
      "Train: (1200, 50, 1), Val: (400, 50, 1), Test: (400, 50, 1)\n",
      "WARNING:tensorflow:From c:\\Users\\lohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model architecture ready\n",
      "WARNING:tensorflow:From c:\\Users\\lohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "13/13 [==============================] - 2s 9ms/step\n",
      "Task-2 complete. Files generated:\n",
      "- lstm_deep_model.h5\n",
      "- lstm_training_curves.png\n",
      "- lstm_confusion_matrix.png\n",
      "- scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Deep Learning LSTM Model - Task 2\")\n",
    "\n",
    "# 1. Generate sequence data for LSTM\n",
    "X, y = make_classification(n_samples=2000, n_features=50, n_informative=30, \n",
    "                          n_redundant=10, n_clusters_per_class=2, random_state=42)\n",
    "\n",
    "# Reshape for LSTM: (samples, timesteps, features)\n",
    "X_seq = X.reshape(2000, 50, 1)\n",
    "y = tf.keras.utils.to_categorical(y, 2)\n",
    "\n",
    "# 2. Train-validation-test split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_seq, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# 3. Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(-1, 1)).reshape(X_train.shape)\n",
    "X_val_scaled = scaler.transform(X_val.reshape(-1, 1)).reshape(X_val.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(-1, 1)).reshape(X_test.shape)\n",
    "\n",
    "# 4. Build Deep Learning LSTM Model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(64, return_sequences=True), input_shape=(50, 1)),\n",
    "    Dropout(0.3),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model architecture ready\")\n",
    "\n",
    "# 5. Training with callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    verbose=0,\n",
    "    callbacks=[reduce_lr]\n",
    ")\n",
    "\n",
    "# 6. Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Loss curves\n",
    "axes[0,0].plot(history.history['loss'], 'b-', linewidth=2, label='Train Loss')\n",
    "axes[0,0].plot(history.history['val_loss'], 'r-', linewidth=2, label='Val Loss')\n",
    "axes[0,0].set_title('LSTM Training: Loss Curves')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "axes[0,1].plot(history.history['accuracy'], 'b-', linewidth=2, label='Train Acc')\n",
    "axes[0,1].plot(history.history['val_accuracy'], 'r-', linewidth=2, label='Val Acc')\n",
    "axes[0,1].set_title('LSTM Training: Accuracy Curves')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Final metrics\n",
    "train_acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "axes[1,0].bar(['Train Acc', 'Val Acc'], [train_acc, val_acc], \n",
    "              color=['#4CAF50', '#2196F3'], alpha=0.8, edgecolor='black')\n",
    "axes[1,0].set_title('Final Performance')\n",
    "axes[1,0].set_ylabel('Accuracy')\n",
    "\n",
    "# Learning rate (approximate)\n",
    "lr_changes = [0.001] + [0.001 * (0.2)**i for i in range(1, 10)]\n",
    "axes[1,1].plot(lr_changes[:15], 'g-', linewidth=2)\n",
    "axes[1,1].set_title('Learning Rate Schedule')\n",
    "axes[1,1].set_ylabel('Learning Rate')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('lstm_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 7. Test evaluation\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test_labels, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=['Class 0', 'Class 1'],\n",
    "            yticklabels=['Class 0', 'Class 1'],\n",
    "            annot_kws={'size': 20})\n",
    "plt.title('LSTM Deep Learning - Confusion Matrix')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.savefig('lstm_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 8. Save model and scaler\n",
    "model.save('lstm_deep_model.h5')\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
